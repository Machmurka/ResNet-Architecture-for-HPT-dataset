{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nif not os.path.exists('hpt') and os.getcwd() == '/kaggle/working':\n    !git clone https://github.com/Milpo1/hpt\n    os.chdir('hpt')","metadata":{"execution":{"iopub.status.busy":"2024-04-09T10:05:21.775622Z","iopub.execute_input":"2024-04-09T10:05:21.776331Z","iopub.status.idle":"2024-04-09T10:06:07.605034Z","shell.execute_reply.started":"2024-04-09T10:05:21.776293Z","shell.execute_reply":"2024-04-09T10:06:07.603934Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'hpt'...\nremote: Enumerating objects: 33821, done.\u001b[K\nremote: Counting objects: 100% (5591/5591), done.\u001b[K\nremote: Compressing objects: 100% (1599/1599), done.\u001b[K\nremote: Total 33821 (delta 4126), reused 5456 (delta 3992), pack-reused 28230\u001b[K\nReceiving objects: 100% (33821/33821), 687.40 MiB | 23.03 MiB/s, done.\nResolving deltas: 100% (21035/21035), done.\nUpdating files: 100% (88/88), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom matplotlib import image as mpimg\nimport numpy as np\nfrom skimage.transform import resize\ndata_method = 'word' # word / tile\n\nif os.path.exists('data'):\n    import shutil\n    shutil.rmtree('data')","metadata":{"execution":{"iopub.status.busy":"2024-04-09T10:06:07.607418Z","iopub.execute_input":"2024-04-09T10:06:07.608155Z","iopub.status.idle":"2024-04-09T10:06:08.096387Z","shell.execute_reply.started":"2024-04-09T10:06:07.608114Z","shell.execute_reply":"2024-04-09T10:06:08.095159Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"if data_method == 'word':\n        # A program for reading and displaying handwritten words downloaded from graphic \n    # files based on descriptions from text files\n    import os\n    from skimage.transform import resize\n    from matplotlib import image as mpimg\n    def trim_image(image, trim_percentage=0.9):\n        new_height = int(image.shape[0] * trim_percentage)\n        new_width = int(image.shape[1] * trim_percentage)\n\n        offset_height = (image.shape[0] - new_height) // 2\n        offset_width = (image.shape[1] - new_width) // 2\n\n        cropped_image = image[offset_height:offset_height+new_height, offset_width:offset_width+new_width]\n\n        return cropped_image\n    num_of_authors = 8\n    # max_num_of_words_per_author = 400000\n\n    def crop(n, max_n):\n        return max(0,n) if n <= max_n else max_n\n\n    def merge(l, start, end):\n        sub_merged = \"\"\n        for o in l[start:end+1]:\n            sub_merged = sub_merged+o\n        merged = l[:start] + [sub_merged] + l[end+1:]\n        return merged\n    h_l, w_l = [], []\n    for author_no in range(num_of_authors):\n        file_desc_name = \"sources/author\" + str(author_no + 1) + \"/word_places.txt\"\n        file_desc_ptr = open(file_desc_name, 'r', errors='ignore')\n        text = file_desc_ptr.read()\n        lines = text.split('\\n')\n        number_of_lines = lines.__len__() - 1\n        row_values = lines[0].split()\n        number_of_values = row_values.__len__()\n\n        num_of_words = 0\n        image_file_name_prev = \"\"\n        subimage_dir = 'data/'+'a'+str(author_no + 1)\n\n        if not os.path.exists(subimage_dir):\n            os.makedirs(subimage_dir)   \n\n        for i in range(number_of_lines):\n            row_values = lines[i].split()\n\n            if len(row_values) > 6:\n                row_values = merge(row_values,1,len(row_values)-5)\n            elif len(row_values) < 6:\n                continue\n\n            if row_values[0] != '%':\n                num_of_words += 1\n                number_of_values = len(row_values)\n\n                image_file_name = \"sources/author\" + str(author_no + 1) + \"/\" + row_values[0][1:-1].replace('\\\\','/')\n\n                if image_file_name != image_file_name_prev:   \n                    image = mpimg.imread(str(image_file_name))\n                    image_file_name_prev = image_file_name\n                word = row_values[1]\n\n                if word == \"<brak>\":\n                    continue\n\n                row1, column1, row2, column2 = int(row_values[2]), int(row_values[3]), \\\n                    int(row_values[4]), int(row_values[5])\n\n                height, width = len(image), len(image[0])\n                row1, row2 =  crop(row1,height), crop(row2,height)\n                column1, column2 =  crop(column1,width), crop(column2,width)\n\n                subimage = image[min(row1,row2):max(row1,row2),\n                                min(column1,column2):max(column1,column2)] \n#                 subimage = trim_image(subimage,0.95)\n                h_l.append(len(subimage))\n                w_l.append(len(subimage[0]))\n\n                #subimage = resize(subimage, (65,154))\n                mpimg.imsave(subimage_dir+'/'+str(num_of_words)+'.bmp',subimage)\n\n            # if num_of_words >= max_num_of_words_per_author: break\n\n\n        file_desc_ptr.close()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-09T10:06:08.097977Z","iopub.execute_input":"2024-04-09T10:06:08.098545Z","iopub.status.idle":"2024-04-09T10:06:16.651589Z","shell.execute_reply.started":"2024-04-09T10:06:08.098515Z","shell.execute_reply":"2024-04-09T10:06:16.650511Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"if data_method == 'tile':\n    num_of_authors = 8\n\n    hor_tile = 8\n    th = 0.92\n    def is_empty_subimage(subimage, threshold=th):\n        gray_subimage = np.mean(subimage, axis=2)\n\n        white_pixels = np.sum(gray_subimage > 220)\n        total_pixels = gray_subimage.shape[0] * gray_subimage.shape[1]\n        white_percentage = white_pixels / total_pixels\n\n        return white_percentage > threshold\n\n    def trim_image(image, trim_percentage=0.9):\n        new_height = int(image.shape[0] * trim_percentage)\n        new_width = int(image.shape[1] * trim_percentage)\n\n        offset_height = (image.shape[0] - new_height) // 2\n        offset_width = (image.shape[1] - new_width) // 2\n\n        cropped_image = image[offset_height:offset_height+new_height, offset_width:offset_width+new_width]\n\n        return cropped_image\n\n    print(f'th: {th} hor tile: {hor_tile}')\n    if os.path.exists('data'):\n        import shutil\n        shutil.rmtree('data')\n    for author_no in range(num_of_authors):\n        source_dir = 'sources/author'+str(author_no + 1)+'/skany'\n        label_dir = 'data/'+'a'+str(author_no + 1)\n        if not os.path.exists(label_dir):\n            os.makedirs(label_dir)  \n        files = os.listdir(source_dir)\n        image_files = [file for file in files if file.endswith('bmp')]\n        subimage_no = 0\n        for image_file in image_files:\n            image_file_name = source_dir + \"/\" + image_file\n            image = mpimg.imread(str(image_file_name))\n            image = trim_image(image)\n            image_h, image_w = len(image), len(image[0])\n            ver_tile = int(hor_tile * image_h/image_w)\n            tile_size = int(image_w / hor_tile)\n            for yp in range(ver_tile):\n                for xp in range(hor_tile):\n                    subimage = image[yp*tile_size:(yp+1)*tile_size,\n                                     xp*tile_size:(xp+1)*tile_size]\n\n                    if not is_empty_subimage(subimage):\n                        subimage_no+=1\n                        mpimg.imsave(label_dir+'/'+str(subimage_no)+'.bmp',subimage)     \n        print(f'Subimages for label {author_no}: {subimage_no}')","metadata":{"execution":{"iopub.status.busy":"2024-04-09T10:06:16.654159Z","iopub.execute_input":"2024-04-09T10:06:16.654911Z","iopub.status.idle":"2024-04-09T10:06:16.667896Z","shell.execute_reply.started":"2024-04-09T10:06:16.654869Z","shell.execute_reply":"2024-04-09T10:06:16.666909Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import  DataLoader, random_split\nclass AuthorImagesDataset:\n    def __init__(self, root_dir, batch_size:int,DataProcent:float,transform=None):\n        self.BATCH_SIZE=batch_size\n        self.root_dir = root_dir\n        self.transform = transform if transform else transforms.ToTensor()\n        self.dataset = datasets.ImageFolder(root=self.root_dir, transform=self.transform)\n\n        subset_length = int(len(self.dataset) * DataProcent)\n        rest_length = len(self.dataset) - subset_length\n        self.subset_data, _ = random_split(self.dataset, [subset_length, rest_length])\n\n\n        test_length = int(len(self.subset_data) * 0.2)\n        train_length = len(self.subset_data) - test_length\n\n        # Split the dataset\n        self.train_data, self.test_data = random_split(self.subset_data, [train_length, test_length])\n        \n        self.into_data_loaders()\n\n    def into_data_loaders(self):\n\n\n        self.train_dataloader= DataLoader(dataset=self.train_data, # use custom created train Dataset\n                                     batch_size=self.BATCH_SIZE, # how many samples per batch?\n                                    num_workers=4, # how many subprocesses to use for data loading? (higher = more)\n                                    # pin_memory=True,\n                                     shuffle=True) # shuffle the data?\n\n        self.test_dataloader = DataLoader(dataset=self.test_data, # use custom created test Dataset\n                                    batch_size=self.BATCH_SIZE, \n                                    num_workers=4, \n                                    shuffle=False) # don't usually need to shuffle testing data\n        \n        \n        # word,label=next(iter(self.test_dataloader))\n        # print(f\"shape of dataloader {word.shape} \\n and label {label}\")\n\n        \n    \n    def __len__(self):\n        return len(self.dataset) \n            \n\n\n# if __name__=='__main__':\n#     t=RawData()\n#     t.save_words_to_file(8)\n#     s=AuthorImagesDataset(r'Data/Words',transform=transforms.Compose([\n#             transforms.Resize(size=(64,64)),\n#             transforms.TrivialAugmentWide(num_magnitude_bins=31),\n#             transforms.ToTensor()\n#         ]))\n    \n\ndef create_dataloaders(\n        DatasetDir:str,\n        transform: transforms.Compose, \n        batch_size: int,\n        DataProcent:float\n):\n    # t=RawData()\n    # t.save_words_to_file(8)\n    s=AuthorImagesDataset(DatasetDir,batch_size,DataProcent,transform)\n    \n    return s.train_dataloader,s.test_dataloader,s.dataset.classes","metadata":{"execution":{"iopub.status.busy":"2024-04-09T10:06:16.669133Z","iopub.execute_input":"2024-04-09T10:06:16.669477Z","iopub.status.idle":"2024-04-09T10:06:24.229480Z","shell.execute_reply.started":"2024-04-09T10:06:16.669445Z","shell.execute_reply":"2024-04-09T10:06:24.228396Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nContains functions for training and testing a PyTorch model.\n\"\"\"\n\nimport torch\nfrom tqdm.auto import tqdm\nfrom typing import Dict, List, Tuple\n\ndef train_step(model: torch.nn.Module, \n               dataloader: torch.utils.data.DataLoader, \n               loss_fn: torch.nn.Module, \n               optimizer: torch.optim.Optimizer,\n               device: torch.device) -> Tuple[float, float]:\n    \n    \n    model.train()\n    train_loss,train_acc=0,0\n\n    for batch, (X,y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n        \n        y_logits=model(X)\n\n        loss=loss_fn(y_logits,y)\n        train_loss+=loss.item()\n\n\n        optimizer.zero_grad()\n\n        loss.backward()\n\n        optimizer.step()\n        \n        y_pred_class=y_logits.argmax(dim=1)\n        train_acc+=(y_pred_class==y).sum().item()/len(y_logits)\n\n    train_loss=train_loss/len(dataloader)\n    train_acc=train_acc/len(dataloader)\n    \n    return train_loss,train_acc\n\n\ndef test_step(model: torch.nn.Module, \n              dataloader: torch.utils.data.DataLoader, \n              loss_fn: torch.nn.Module,\n              device: torch.device) -> Tuple[float, float]:\n    \n    model.eval()\n    test_loss,test_acc=0,0\n\n    with torch.inference_mode():\n        for batch, (X,y) in enumerate(dataloader):\n            X, y = X.to(device), y.to(device)\n            y_logits=model(X)\n            \n            loss=loss_fn(y_logits,y)\n            test_loss+=loss.item()\n\n            y_pred_class=y_logits.argmax(dim=1)\n            test_acc+=(y_pred_class==y).sum().item()/len(y_logits)\n\n    test_loss=test_loss/len(dataloader)\n    test_acc=test_acc/len(dataloader)\n\n    return test_loss,test_acc\n\n\ndef train(model: torch.nn.Module, \n          train_dataloader: torch.utils.data.DataLoader, \n          test_dataloader: torch.utils.data.DataLoader, \n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device) -> Dict[str, List]:\n    \n    results = {\"train_loss\": [],\n    \"train_acc\": [],\n    \"test_loss\": [],\n    \"test_acc\": []\n    }\n\n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc = train_step(model=model,\n                                            dataloader=train_dataloader,\n                                            loss_fn=loss_fn,\n                                            optimizer=optimizer,\n                                            device=device)\n        test_loss, test_acc = test_step(model=model,\n            dataloader=test_dataloader,\n            loss_fn=loss_fn,\n            device=device)\n\n        print(\n            f\"Epoch: {epoch+1} | \"\n            f\"train_loss: {train_loss:.4f} | \"\n            f\"train_acc: {train_acc:.4f} | \"\n            f\"test_loss: {test_loss:.4f} | \"\n            f\"test_acc: {test_acc:.4f}\"\n        )\n\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n        if train_acc >= 0.99 and test_acc >= 0.99:\n            return results\n    return results\n\n\n\ndef plot_loss_curves(results: Dict[str, List[float]]):\n    import matplotlib.pyplot as plt\n    \"\"\"Plots training curves of a results dictionary.\n\n    Args:\n        results (dict): dictionary containing list of values, e.g.\n            {\"train_loss\": [...],\n             \"train_acc\": [...],\n             \"test_loss\": [...],\n             \"test_acc\": [...]}\n    \"\"\"\n    \n    # Get the loss values of the results dictionary (training and test)\n    loss = results['train_loss']\n    test_loss = results['test_loss']\n\n    # Get the accuracy values of the results dictionary (training and test)\n    accuracy = results['train_acc']\n    test_accuracy = results['test_acc']\n\n    # Figure out how many epochs there were\n    epochs = range(len(results['train_loss']))\n\n    # Setup a plot \n    plt.figure(figsize=(15, 7))\n\n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, loss, label='train_loss')\n    plt.plot(epochs, test_loss, label='test_loss')\n\n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.legend()\n    # plt.show()\n\n    # Plot accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, accuracy, label='train_accuracy')\n    plt.plot(epochs, test_accuracy, label='test_accuracy')\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-09T10:06:24.231157Z","iopub.execute_input":"2024-04-09T10:06:24.231608Z","iopub.status.idle":"2024-04-09T10:06:24.257848Z","shell.execute_reply.started":"2024-04-09T10:06:24.231580Z","shell.execute_reply":"2024-04-09T10:06:24.256716Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nContains PyTorch model code to ResNet50-ResNet152 models.\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms\n\nclass ResNetblock(nn.Module):\n    '''\n        Również do opisania ładnego teraz wyjebane jajca nie mam czasu na tłumaczenie tego gówna eeeelo\n    '''\n    def __init__(self,in_channels,out_channels,stride=1,identity_downsample=None) -> None:\n        super(ResNetblock,self).__init__()\n\n        self.expansion=4\n\n        self.conv1=nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=3,padding=1,stride=stride)\n        self.bn1=nn.BatchNorm2d(out_channels)\n       \n        self.conv2=nn.Conv2d(in_channels=out_channels,out_channels=out_channels,kernel_size=3,padding=1,stride=1)\n        self.bn2=nn.BatchNorm2d(out_channels)\n       \n        self.conv3=nn.Conv2d(in_channels=out_channels,out_channels=out_channels*self.expansion,kernel_size=3,padding=1,stride=1)\n        self.bn3=nn.BatchNorm2d(out_channels*self.expansion)\n        \n        \n        self.relu=nn.ReLU()\n\n        self.identity_downsample=identity_downsample\n    \n    def forward(self,x):\n        identity=x\n        # print(f\"identity shape x{identity.shape}\")\n        \n        x=self.conv1(x)\n        x=self.bn1(x)\n        x=self.relu(x)\n        # print(f\"after conv1 shape {x.shape}\")\n\n        x=self.conv2(x)\n        x=self.bn2(x)\n        # print(f\"after conv2 shape {x.shape}\")\n\n        # print(f\"before conv3 shape {x.shape}\")\n        x=self.conv3(x)\n        x=self.bn3(x)\n        # print(f\"after conv3 shape {x.shape}\")\n        \n        if self.identity_downsample != None:\n            identity=self.identity_downsample(identity)\n            # print(f\"identity shape after downsample {identity.shape}\")\n\n        x+=identity\n        x=self.relu(x)\n        # print(f\"x shape {x.shape}\")\n\n        return x\n    \n\n\nclass ResNet(nn.Module):\n    '''\n        Creates the ResNet50+ architecture\n\n        Replicates the ResNet50 architecture from the https://github.com/Machmurka/UnderstandingDeepLearning/blob/main/Learn%20PyTorch%20for%20Deep%20Learning/ResNet18layers.ipynb\n        See the original architecture here: # https://arxiv.org/pdf/1512.03385.pdf\n\n          Args:\n            block: ResNetblock class\n            # do napisania teraz wyjebane jajca\n    '''\n    def __init__(self,block:ResNetblock,img_channels,num_classes,block_num:list) -> None:\n        super(ResNet,self).__init__()\n        \n        self.in_channels=64\n \n        self.conv1=nn.Conv2d(img_channels,64,kernel_size=7,stride=2,padding=3)\n        self.bn1=nn.BatchNorm2d(64)\n        self.relu=nn.ReLU()\n        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n\n        self.layer2=self._make_layer(block,block_num[0],64,1)\n        self.layer3=self._make_layer(block,block_num[1],128,2)\n        self.layer4=self._make_layer(block,block_num[2],256,2)\n        self.layer5=self._make_layer(block,block_num[3],512,2)\n\n        self.avg=nn.AvgPool2d((1,1))\n        self.fc=nn.Linear(128*128*2,num_classes)\n\n\n    def forward(self,x):\n        x=self.conv1(x)\n        x=self.bn1(x)\n        x=self.relu(x)\n        x=self.maxpool(x)\n\n        x=self.layer2(x)\n        x=self.layer3(x)\n        x=self.layer4(x)\n        x=self.layer5(x)\n        x=self.avg(x)\n        x=x.reshape(x.shape[0],-1)\n        x=self.fc(x)\n        \n\n\n        # print(f\"shape after layer1 {x.shape}\")\n        # print(\"\\n\\n LAYER 2 \\n\\n\")\n        # x=self.layer2(x)\n        # print(f\"shape after layer2 {x.shape}\")\n        # print(\"\\n\\n LAYER 3 \\n\\n\")  \n        # x=self.layer3(x)\n        # print(f\"shape after layer3 {x.shape}\")\n        # print(\"\\n\\n LAYER 4 \\n\\n\")  \n        # x=self.layer4(x)\n        # print(f\"shape after layer4 {x.shape}\")\n        # print(\"\\n\\n LAYER 5 \\n\\n\")  \n        # x=self.layer5(x)\n        # print(f\"shape after layer5 {x.shape}\")\n        # x=self.avg(x)\n        # print(f\"shape after avg {x.shape}\")\n        # x=x.reshape(x.shape[0],-1)\n        # print(f\"shape after reshape {x.shape}\")\n        # x=self.fc(x)\n        # print(f\"output shape {x.shape}\")\n        \n        return x\n    \n    def _make_layer(self,block:ResNetblock,num_blocks,out_channels,stride):\n        identity_downsample=None\n        layers=[]\n\n        if stride!=1 or self.in_channels!=out_channels*4:\n            identity_downsample=nn.Sequential(\n                nn.Conv2d(self.in_channels,out_channels*4,1,stride,padding=0),\n                nn.BatchNorm2d(out_channels*4)\n            )\n            # print(\"stride test\")\n        \n        layers.append(block(self.in_channels,out_channels=out_channels,stride=stride,identity_downsample=identity_downsample))\n        self.in_channels=out_channels*4\n\n        for i in range(num_blocks-1):\n            layers.append(block(self.in_channels,out_channels=out_channels))\n\n        return nn.Sequential(*layers)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T10:06:24.259437Z","iopub.execute_input":"2024-04-09T10:06:24.259745Z","iopub.status.idle":"2024-04-09T10:06:24.285153Z","shell.execute_reply.started":"2024-04-09T10:06:24.259703Z","shell.execute_reply":"2024-04-09T10:06:24.284191Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nTrains a PyTorch image classification model using device-agnostic code.\n\"\"\"\n\nimport os\nimport torch\nfrom torchvision import transforms\nimport torchvision.models as models\n# Porcent wykorzystania całych danych\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndata_dir='data'\nprint(device)\n\nDATA_PROCENT=1\nNUM_EPOCHS = 40\nBATCH_SIZE = 128\nLEARNING_RATE = 0.0001\nBLOCK_NUM=[3,4,23,3]\n\ndata_transform= transforms.Compose([transforms.Resize(size=(128,128)),\n                #transforms.TrivialAugmentWide(num_magnitude_bins=31),\n                transforms.ToTensor()\n                ])\n\ntrain_dataloader, test_dataloader, class_names = create_dataloaders(\n    DatasetDir=data_dir,\n    transform=data_transform,\n    batch_size=BATCH_SIZE,\n    DataProcent=DATA_PROCENT\n)\nmodel = ResNet(ResNetblock,3,len(class_names),BLOCK_NUM)\nmodel = nn.DataParallel(model)\nmodel = model.to(device)\nmodel.train()\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T10:06:24.286467Z","iopub.execute_input":"2024-04-09T10:06:24.286790Z","iopub.status.idle":"2024-04-09T10:06:26.683193Z","shell.execute_reply.started":"2024-04-09T10:06:24.286766Z","shell.execute_reply":"2024-04-09T10:06:26.682411Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"len train_dataloader {len(train_dataloader)*BATCH_SIZE}\")\nprint(f\"len test_dataloader {len(test_dataloader)*BATCH_SIZE}\")\n\nresults=train(model=model,\n                    train_dataloader=train_dataloader,\n                    test_dataloader=test_dataloader,\n                    loss_fn=loss_fn,\n                    optimizer=optimizer,\n                    epochs=NUM_EPOCHS,\n                    device=device)\n\n# train_features_batch, train_labels_batch = next(iter(train_dataloader))\n\nplot_loss_curves(results)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T10:06:26.684944Z","iopub.execute_input":"2024-04-09T10:06:26.685329Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"len train_dataloader 11392\nlen test_dataloader 2944\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af8843fb2aa64a3784556ce1142ee7c3"}},"metadata":{}},{"name":"stdout","text":"Epoch: 1 | train_loss: 1.1410 | train_acc: 0.6688 | test_loss: 0.3109 | test_acc: 0.8815\nEpoch: 2 | train_loss: 0.4363 | train_acc: 0.8784 | test_loss: 0.2211 | test_acc: 0.9293\nEpoch: 3 | train_loss: 0.2685 | train_acc: 0.9181 | test_loss: 0.2148 | test_acc: 0.9263\nEpoch: 4 | train_loss: 0.1475 | train_acc: 0.9474 | test_loss: 0.1399 | test_acc: 0.9501\nEpoch: 5 | train_loss: 0.0985 | train_acc: 0.9656 | test_loss: 0.1685 | test_acc: 0.9423\nEpoch: 6 | train_loss: 0.0824 | train_acc: 0.9718 | test_loss: 0.1455 | test_acc: 0.9385\nEpoch: 7 | train_loss: 0.0728 | train_acc: 0.9768 | test_loss: 0.2290 | test_acc: 0.9253\nEpoch: 8 | train_loss: 0.1043 | train_acc: 0.9688 | test_loss: 0.7467 | test_acc: 0.7935\nEpoch: 9 | train_loss: 0.4828 | train_acc: 0.9273 | test_loss: 1.7975 | test_acc: 0.7330\nEpoch: 10 | train_loss: 0.2146 | train_acc: 0.9345 | test_loss: 0.1920 | test_acc: 0.9355\nEpoch: 11 | train_loss: 0.1595 | train_acc: 0.9613 | test_loss: 0.1335 | test_acc: 0.9562\nEpoch: 12 | train_loss: 0.0742 | train_acc: 0.9803 | test_loss: 0.0502 | test_acc: 0.9834\nEpoch: 13 | train_loss: 0.0424 | train_acc: 0.9853 | test_loss: 0.0587 | test_acc: 0.9793\nEpoch: 14 | train_loss: 0.0352 | train_acc: 0.9876 | test_loss: 0.0551 | test_acc: 0.9857\nEpoch: 15 | train_loss: 0.0369 | train_acc: 0.9868 | test_loss: 1.2951 | test_acc: 0.7327\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\nimport torch\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Get some images from the training set\ndataiter = iter(train_dataloader)\nimages, labels = next(dataiter)\n\n# Select a subset of images to display\nrand = random.randint(0,32)\nimages_subset, labels_subset = images[rand:rand+5], labels[rand:rand+5]\n\n# Predict\nwith torch.no_grad():  # We don't need to calculate gradients here, so we disable gradient computation\n    #images_flattened = images_subset.view(-1, input_size)\n    outputs = model(images_subset)\n    _, predicted = torch.max(outputs, 1)\n\n# Plot the images along with predicted and true labels\nfig, axes = plt.subplots(1, 5, figsize=(12, 2.5))\nfor ax, image, pred, true in zip(axes, images_subset, predicted, labels_subset):\n    image_np = image.cpu().numpy().transpose((1,2,0))\n    image_np = image_np * 0.5 + 0.5\n    ax.imshow(image_np)\n    \n    ax.set_title(f'Predicted: {pred}\\nTrue: {true}')\n    ax.axis('off')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_cat_step(model: torch.nn.Module, \n              dataloader: torch.utils.data.DataLoader, \n              loss_fn: torch.nn.Module,\n              device: torch.device,\n              num_classes: int) -> Tuple[float, torch.Tensor]:\n    \n    model.eval()\n    test_loss = 0\n    correct_predictions = torch.zeros(num_classes, dtype=torch.float32, device=device)\n    total_predictions = torch.zeros(num_classes, dtype=torch.float32, device=device)\n\n    with torch.inference_mode():\n        for batch, (X, y) in enumerate(dataloader):\n            X, y = X.to(device), y.to(device)\n            y_logits = model(X)\n            \n            loss = loss_fn(y_logits, y)\n            test_loss += loss.item()\n            \n            y_pred_class = y_logits.argmax(dim=1)\n            \n            for category in range(num_classes):\n                category_mask = y == category\n                correct_predictions[category] += (y_pred_class[category_mask] == y[category_mask]).sum().item()\n                total_predictions[category] += category_mask.sum().item()\n\n    test_loss = test_loss / len(dataloader)\n    test_acc = correct_predictions / total_predictions\n\n    return test_loss, test_acc\ntest_cat_step(model=model,\n            dataloader=train_dataloader,\n            loss_fn=loss_fn,\n            device=device,\n            num_classes=8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model,'resnet101.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}